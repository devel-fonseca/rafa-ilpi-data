/**
 * Servi√ßo de Detec√ß√£o Facial usando BlazeFace (TensorFlow.js)
 *
 * Funcionalidades:
 * - Detecta rostos em imagens
 * - Calcula posi√ß√£o e tamanho do rosto
 * - Gera crop inteligente centralizado no rosto
 * - Adiciona margem de 30% para contexto
 * - Fallback para crop centralizado se n√£o detectar rosto
 */

type BlazeFaceModule = typeof import('@tensorflow-models/blazeface')
type TensorflowModule = typeof import('@tensorflow/tfjs')

let blazefaceModule: BlazeFaceModule | null = null
let tfModule: TensorflowModule | null = null
let model: import('@tensorflow-models/blazeface').BlazeFaceModel | null = null
let isLoading = false
let loadError = false

/**
 * Carrega o modelo BlazeFace (lazy loading)
 * Modelo √© pequeno (~1MB) e r√°pido de carregar
 */
export async function loadFaceDetectionModel(): Promise<import('@tensorflow-models/blazeface').BlazeFaceModel | null> {
  // Se j√° teve erro antes, n√£o tenta novamente
  if (loadError) {
    console.warn('‚ö†Ô∏è Detec√ß√£o facial desabilitada devido a erro anterior')
    return null
  }

  if (model) return model

  if (isLoading) {
    // Aguarda o modelo j√° em carregamento
    while (isLoading) {
      await new Promise((resolve) => setTimeout(resolve, 100))
    }
    return model
  }

  try {
    isLoading = true
    console.log('üîÑ Carregando modelo BlazeFace...')

    if (!blazefaceModule || !tfModule) {
      const [blazefaceImported, tfImported] = await Promise.all([
        import('@tensorflow-models/blazeface'),
        import('@tensorflow/tfjs'),
      ])
      blazefaceModule = blazefaceImported
      tfModule = tfImported
    }

    // Configurar backend do TensorFlow.js
    await tfModule.ready()
    console.log('üîÑ TensorFlow.js backend:', tfModule.getBackend())

    // Carregar modelo com timeout de 10 segundos
    const loadPromise = blazefaceModule.load()
    const timeoutPromise = new Promise<never>((_, reject) =>
      setTimeout(() => reject(new Error('Timeout ao carregar modelo')), 10000)
    )

    model = await Promise.race([loadPromise, timeoutPromise])

    console.log('‚úÖ Modelo BlazeFace carregado com sucesso')
    return model
  } catch (error) {
    loadError = true
    console.warn(
      '‚ö†Ô∏è N√£o foi poss√≠vel carregar o modelo de detec√ß√£o facial. A aplica√ß√£o continuar√° funcionando com crop centralizado.',
      error
    )
    return null
  } finally {
    isLoading = false
  }
}

interface FaceDetectionResult {
  hasFace: boolean
  cropData: {
    x: number
    y: number
    width: number
    height: number
  }
  confidence?: number
}

/**
 * Detecta rosto em uma imagem e retorna coordenadas de crop
 * @param imageElement - Elemento <img> ou HTMLImageElement
 * @returns Dados do crop (com ou sem detec√ß√£o de rosto)
 */
export async function detectFaceAndCrop(
  imageElement: HTMLImageElement,
): Promise<FaceDetectionResult> {
  try {
    // Carregar modelo se necess√°rio
    const faceModel = await loadFaceDetectionModel()

    // Se modelo n√£o carregou, usar fallback
    if (!faceModel) {
      console.log('‚ö†Ô∏è Modelo n√£o dispon√≠vel - usando crop centralizado')
      return getFallbackCrop(imageElement)
    }

    // Detectar rostos
    const predictions = await faceModel.estimateFaces(imageElement, false)

    if (predictions.length === 0) {
      console.log('‚ö†Ô∏è Nenhum rosto detectado - usando crop centralizado')
      return getFallbackCrop(imageElement)
    }

    // Usar primeiro rosto detectado (maior confian√ßa)
    const face = predictions[0]

    // Coordenadas do bounding box
    const [x1, y1] = face.topLeft as [number, number]
    const [x2, y2] = face.bottomRight as [number, number]

    const faceWidth = x2 - x1
    const faceHeight = y2 - y1

    // Margens assim√©tricas em n√≠vel moderado:
    // preserva a testa sem "afastar" excessivamente o rosto.
    const sideMargin = faceWidth * 0.25
    const topMargin = faceHeight * 0.42
    const bottomMargin = faceHeight * 0.22

    const expandedLeft = x1 - sideMargin
    const expandedRight = x2 + sideMargin
    const expandedTop = y1 - topMargin
    const expandedBottom = y2 + bottomMargin

    const expandedWidth = expandedRight - expandedLeft
    const expandedHeight = expandedBottom - expandedTop

    // Garantir propor√ß√£o 1:1 (quadrado) e respeitar limites da imagem
    const cropSize = Math.min(
      Math.max(expandedWidth, expandedHeight),
      imageElement.width,
      imageElement.height,
    )

    // Centro com vi√©s suave para cima (mais discreto que a vers√£o anterior)
    const faceCenterX = x1 + faceWidth / 2
    const faceCenterY = y1 + faceHeight * 0.48

    let cropX = faceCenterX - cropSize / 2
    let cropY = faceCenterY - cropSize / 2

    // Ajustar se ultrapassar bordas
    if (cropX < 0) cropX = 0
    if (cropY < 0) cropY = 0
    if (cropX + cropSize > imageElement.width) {
      cropX = imageElement.width - cropSize
    }
    if (cropY + cropSize > imageElement.height) {
      cropY = imageElement.height - cropSize
    }

    console.log('‚úÖ Rosto detectado com sucesso')

    return {
      hasFace: true,
      cropData: {
        x: Math.round(cropX),
        y: Math.round(cropY),
        width: Math.round(cropSize),
        height: Math.round(cropSize),
      },
      confidence: face.probability ? face.probability[0] : undefined,
    }
  } catch (error) {
    console.error('‚ùå Erro na detec√ß√£o facial:', error)
    // Fallback para crop centralizado em caso de erro
    return getFallbackCrop(imageElement)
  }
}

/**
 * Retorna crop centralizado (fallback quando n√£o detecta rosto)
 */
function getFallbackCrop(imageElement: HTMLImageElement): FaceDetectionResult {
  const size = Math.min(imageElement.width, imageElement.height)
  const x = (imageElement.width - size) / 2
  const y = (imageElement.height - size) / 2

  return {
    hasFace: false,
    cropData: {
      x: Math.round(x),
      y: Math.round(y),
      width: Math.round(size),
      height: Math.round(size),
    },
  }
}

/**
 * Aplica crop na imagem usando canvas
 * @param imageElement - Imagem original
 * @param cropData - Coordenadas do crop
 * @param outputSize - Tamanho final da imagem (padr√£o: 300x300)
 * @returns Blob da imagem cropada em WebP
 */
export async function applyCrop(
  imageElement: HTMLImageElement,
  cropData: { x: number; y: number; width: number; height: number },
  outputSize: number = 300,
): Promise<Blob> {
  return new Promise((resolve, reject) => {
    const canvas = document.createElement('canvas')
    canvas.width = outputSize
    canvas.height = outputSize

    const ctx = canvas.getContext('2d')
    if (!ctx) {
      reject(new Error('N√£o foi poss√≠vel criar contexto do canvas'))
      return
    }

    // Desenhar crop da imagem original redimensionado para outputSize
    ctx.drawImage(
      imageElement,
      cropData.x,
      cropData.y,
      cropData.width,
      cropData.height,
      0,
      0,
      outputSize,
      outputSize,
    )

    // Converter para WebP
    canvas.toBlob(
      (blob) => {
        if (blob) {
          resolve(blob)
        } else {
          reject(new Error('Erro ao gerar blob da imagem'))
        }
      },
      'image/webp',
      0.95, // Qualidade 95%
    )
  })
}

/**
 * Pipeline completo: detecta rosto, aplica crop e retorna blob
 * @param file - Arquivo original
 * @returns Blob da imagem processada
 */
export async function processImageWithFaceDetection(
  file: File,
): Promise<{
  blob: Blob
  hasFace: boolean
  confidence?: number
}> {
  return new Promise((resolve, reject) => {
    const img = new Image()
    const reader = new FileReader()

    reader.onload = async (e) => {
      img.src = e.target?.result as string

      img.onload = async () => {
        try {
          // Detectar rosto
          const detection = await detectFaceAndCrop(img)

          // Aplicar crop
          const blob = await applyCrop(img, detection.cropData, 300)

          resolve({
            blob,
            hasFace: detection.hasFace,
            confidence: detection.confidence,
          })
        } catch (error) {
          reject(error)
        }
      }

      img.onerror = () => reject(new Error('Erro ao carregar imagem'))
    }

    reader.onerror = () => reject(new Error('Erro ao ler arquivo'))
    reader.readAsDataURL(file)
  })
}

/**
 * Limpa recursos do TensorFlow.js (chamar ao desmontar componente)
 */
export function cleanupFaceDetection() {
  if (model) {
    model = null
    tf.disposeVariables()
    console.log('üßπ Recursos de detec√ß√£o facial liberados')
  }
}
